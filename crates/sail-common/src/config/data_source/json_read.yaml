# References:
#   - [1] https://spark.apache.org/docs/4.0.0/sql-data-sources-json.html#data-source-option
#   - [2] https://github.com/apache/spark/blob/b0c2ba357bf080dd328b95e4a6402b134a641a1a/python/pyspark/sql/connect/readwriter.py#L146-L174

- key: schema_infer_max_records
  alias:
    - schemaInferMaxRecords
  default: "1000"
  description: |
    The maximum number of rows to read from CSV files for schema inference if needed.
  supported: true

- key: compression
  default: "UNCOMPRESSED"
  description: |
    Specifies the file compression type. The following compression types are supported:
      - `GZIP` or `GZ`
      - `BZIP2` or `BZ2`
      - `XZ`
      - `ZSTD` or `ZST`
      - `UNCOMPRESSED` or ""
  supported: true