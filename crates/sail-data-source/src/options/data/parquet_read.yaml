# References:
#   - [1] https://spark.apache.org/docs/4.0.0/sql-data-sources-parquet.html#data-source-option
#   - [2] https://github.com/apache/spark/blob/b0c2ba357bf080dd328b95e4a6402b134a641a1a/python/pyspark/sql/connect/readwriter.py#L207-L214

# TODO: Spark global: https://spark.apache.org/docs/4.0.0/sql-data-sources-parquet.html#configuration
# TODO: DataFusion `column_specific_options` and `key_value_metadata`

- key: enable_page_index
  aliases:
    - enablePageIndex
  description: |
    (Reading) Whether to enable page index when reading Parquet files.
    If the value is `true`, the Parquet reader reads the page index if present.
    This can reduce I/O and the number of rows decoded.
    Defaults to the Sail configuration option `parquet.enable_page_index`.
  supported: true
  rust_type: bool
  rust_deserialize_with: crate::options::serde::deserialize_bool

- key: pruning
  description: |
    (Reading) Whether to prune row groups when reading Parquet files.
    If the value is `true`, the Parquet reader attempts to skip entire row groups based
    on the predicate in the query and the metadata (minimum and maximum values) stored in
    the Parquet file.
    Defaults to the Sail configuration option `parquet.pruning`.
  supported: true
  rust_type: bool
  rust_deserialize_with: crate::options::serde::deserialize_bool

- key: skip_metadata
  aliases:
    - skipMetadata
  description: |
    (Reading) Whether to skip the metadata when reading Parquet files.
    If the value is `true`, the Parquet reader skip the optional embedded metadata that may be in
    the file schema. This can help avoid schema conflicts when querying
    multiple Parquet files with schemas containing compatible types but different metadata.
    Defaults to the Sail configuration option `parquet.skip_metadata`.
  supported: true
  rust_type: bool
  rust_deserialize_with: crate::options::serde::deserialize_bool

- key: metadata_size_hint
  aliases:
    - metadataSizeHint
  description: |
    (Reading) The metadata size hint in bytes when reading Parquet files.
    If the value `n` is greater than `8`, the Parquet reader will try and fetch the last `n`
    bytes of the Parquet file optimistically. Otherwise, two reads are performed to fetch the
    metadata. The first read fetches the 8-byte Parquet footer and the second read fetches
    the metadata length encoded in the footer.
    Defaults to the Sail configuration option `parquet.metadata_size_hint`.
  supported: true
  rust_type: usize
  rust_deserialize_with: crate::options::serde::deserialize_non_zero_usize

- key: pushdown_filters
  aliases:
    - pushdownFilters
  description: |
    (Reading) Whether to push down filter expressions when reading Parquet files.
    If the value is `true`, the Parquet reader applies filter expressions in decoding operations to
    reduce the number of rows decoded. This optimization is sometimes called "late materialization".
    Defaults to the Sail configuration option `parquet.pushdown_filters`.
  supported: true
  rust_type: bool
  rust_deserialize_with: crate::options::serde::deserialize_bool

- key: reorder_filters
  aliases:
    - reorderFilters
  description: |
    (Reading) Whether to reorder filter expressions when reading Parquet files.
    If the value is `true`, the Parquet reader reorders filter expressions heuristically in decoding operations to
    minimize the cost of evaluation. If the value is `false`, the filters are applied in the same order as written in the query.
    Defaults to the Sail configuration option `parquet.reorder_filters`.
  supported: true
  rust_type: bool
  rust_deserialize_with: crate::options::serde::deserialize_bool

- key: schema_force_view_types
  aliases:
    - schemaForceViewTypes
  description: |
    (Reading) Whether to force view types for binary and string columns when reading Parquet files.
    If the value is `true`, the Parquet reader will read columns of the `Utf8` or `Utf8Large` types as the `Utf8View` type,
    and the `Binary` or `BinaryLarge` types as the `BinaryView` type.
    Defaults to the Sail configuration option `parquet.schema_force_view_types`.
  supported: true
  rust_type: bool
  rust_deserialize_with: crate::options::serde::deserialize_bool

- key: binary_as_string
  aliases:
    - binaryAsString
  description: |
    (Reading) Whether to read binary columns as string columns when reading Parquet files.
    If the value is `true`, the Parquet reader will read columns of
    the `Binary` or `LargeBinary` as the `Utf8` type, and the `BinaryView` type as the `Utf8View` type.
    This is helpful when reading Parquet files generated by some legacy writers, which do not correctly set
    the UTF-8 flag for strings, causing string columns to be loaded as binary columns by default.
    Defaults to the Sail configuration option `parquet.binary_as_string`.
  supported: true
  rust_type: bool
  rust_deserialize_with: crate::options::serde::deserialize_bool

- key: coerce_int96
  aliases:
    - coerceInt96
  default: "us"
  description: |
    (Reading) Controls how the parquet reader interprets columns with physical type int96.
    By default, int96 columns are treated as microsecond ("us") resolution timestamps.
    This setting is useful for reading data from systems like Apache Spark, which encode microsecond timestamps
    in int96, enabling a wider date range to be written than with 64-bit timestamps at nanosecond resolution.
    Possible options are:
      - `ns`: interpret as nanoseconds,
      - `us`: interpret as microseconds,
      - `ms`: interpret as milliseconds,
      - `s`: interpret as seconds.
  supported: true

- key: bloom_filter_on_read
  aliases:
    - bloomFilterOnRead
  description: |
    (Reading) Whether to use available bloom filters when reading Parquet files.
    Defaults to the Sail configuration option `parquet.bloom_filter_on_read`.
  supported: true
  rust_type: bool
  rust_deserialize_with: crate::options::serde::deserialize_bool

- key: merge_schema
  aliases:
    - mergeSchema
  description: |
    (Reading) Sets whether we should merge schemas collected from all Parquet part-files.
    Defaults to the Sail configuration option `parquet.merge_schema` (to be implemented).
  supported: false

- key: int96_rebase_mode
  aliases:
    - int96RebaseMode
  description: |
    (Reading) The int96RebaseMode option allows to specify the rebasing mode for INT96 timestamps
    from the Julian to Proleptic Gregorian calendar.
    Currently supported modes are:
      - `EXCEPTION`: Fails in reads of ancient INT96 timestamps that are ambiguous between the two calendars.
      - `CORRECTED`: Loads INT96 timestamps without rebasing.
      - `LEGACY`: Performs rebasing of ancient timestamps from the Julian to Proleptic Gregorian calendar.
    Defaults to the Sail configuration option `parquet.int96_rebase_mode_in_read` (to be implemented).
  supported: false

- key: datetime_rebase_mode
  aliases:
    - datetimeRebaseMode
  description: |
    (Reading) The datetime_rebase_mode option allows to specify the rebasing mode for the values of the
    `DATE`, `TIMESTAMP_MILLIS`, `TIMESTAMP_MICROS` logical types from the Julian to Proleptic Gregorian calendar.
    Currently supported modes are:
      - `EXCEPTION`: Fails in reads of ancient dates/timestamps that are ambiguous between the two calendars.
      - `CORRECTED`: Loads dates/timestamps without rebasing.
      - `LEGACY`: Performs rebasing of ancient dates/timestamps from the Julian to Proleptic Gregorian calendar.
    Defaults to the Sail configuration option `parquet.datetime_rebase_mode_in_read` (to be implemented).
  supported: false
